{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import json\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "from red_utils.constants import IDX_TO_ELEM_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set input and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = \"/home/shtoshni/Research/events/proc_data/red/independent/\"\n",
    "# output_dir = \"/home/shtoshni/Research/events/data/red/bert_html\"\n",
    "input_dir = \"/home/shtoshni/Research/events/models/events_cb030fc0c2b8abdb996fc320c2321144\"\n",
    "base_output_dir = \"/home/shtoshni/Research/events/models/html_vis\"\n",
    "\n",
    "output_dir = path.join(base_output_dir, path.basename(path.normpath(input_dir)))\n",
    "\n",
    "\n",
    "suffix = \"{}.log.jsonl\"\n",
    "\n",
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "# splits = [\"dev\"]\n",
    "\n",
    "\n",
    "if not path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_START = '<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"UTF-8\"></head><body>'\n",
    "\n",
    "\n",
    "start_tag_template = '<div style=\"border:2px; display:inline; border-style: {}; border-color: {}; padding: {}px; padding-right: 3px; padding-left: 3px\">'\n",
    "end_tag = '</div>'\n",
    "\n",
    "largest_padding = 14\n",
    "padding_reduction = 3\n",
    "\n",
    "\n",
    "def get_tag_options(cluster):\n",
    "    border = 'solid'\n",
    "    if len(cluster) == 1:\n",
    "        border = 'dotted'\n",
    "        \n",
    "    color = '#0066CC'\n",
    "    if cluster[0][-1] == 1:\n",
    "        color = 'violet'\n",
    "        \n",
    "    return (border, color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Train\n",
      "Processing Dev\n",
      "Processing Test\n"
     ]
    }
   ],
   "source": [
    "html_files = []\n",
    "\n",
    "for split in splits:\n",
    "    print(f\"Processing {split.capitalize()}\")\n",
    "    # Read the source doc\n",
    "    split_file = path.join(input_dir, suffix.format(split))\n",
    "    \n",
    "    with open(split_file) as f:\n",
    "        for line in f:\n",
    "            instance = json.loads(line.strip())\n",
    "            \n",
    "            bert_seg_idx = []\n",
    "            doc_list = [] \n",
    "            for sentence in instance[\"sentences\"]:\n",
    "                doc_list.extend(sentence)\n",
    "                bert_seg_idx.append(len(sentence) + (bert_seg_idx[-1] if len(bert_seg_idx) else 0))\n",
    "            \n",
    "            bert_seg_idx = set(bert_seg_idx)\n",
    "            html_tag_list = {}\n",
    "\n",
    "            # Get all the entity info\n",
    "            \n",
    "            clusters = sorted(instance[\"clusters\"], key=lambda cluster: min([elem[0] for elem in cluster]))\n",
    "            for cluster_idx, cluster in enumerate(clusters):\n",
    "                for mention in cluster:\n",
    "                    span_start, span_end, ent_type = mention\n",
    "                    span_end = span_end + 1  ## Now span_end is not part of the span\n",
    "                    ent_type = IDX_TO_ELEM_TYPE[ent_type]\n",
    "\n",
    "                    if span_start not in html_tag_list:\n",
    "                        html_tag_list[span_start] = defaultdict(list)\n",
    "                    if span_end not in html_tag_list:\n",
    "                        html_tag_list[span_end] = defaultdict(list)\n",
    "\n",
    "#                     subscript = ''\n",
    "                    subscript = ent_type[:3] + \" \" + str(cluster_idx)\n",
    "                    \n",
    "                    tag_options = get_tag_options(cluster)\n",
    "                    start_tag = start_tag_template.format(*tag_options, \n",
    "                                                          largest_padding - padding_reduction * len(html_tag_list[span_start]['start']))\n",
    "\n",
    "\n",
    "                    html_tag_list[span_start]['start'].append((start_tag))\n",
    "                    # Subscript used in end\n",
    "                    html_tag_list[span_end]['end'].append((span_start, cluster_idx, end_tag, subscript))\n",
    "                \n",
    "            \n",
    "            for cluster_idx, cluster in enumerate(instance[\"predicted_clusters\"]):\n",
    "                for mention in cluster:\n",
    "                    span_start, span_end, ent_type = mention\n",
    "                    span_end = span_end + 1  ## Now span_end is not part of the span\n",
    "                    ent_type = IDX_TO_ELEM_TYPE[ent_type]\n",
    "                    \n",
    "                    if span_start not in html_tag_list:\n",
    "                        html_tag_list[span_start] = defaultdict(list)\n",
    "                    if span_end not in html_tag_list:\n",
    "                        html_tag_list[span_end] = defaultdict(list)\n",
    "\n",
    "#                     subscript = ''\n",
    "                    subscript = \"PRED \" + ent_type[:3] + \" \" + str(cluster_idx)\n",
    "                    \n",
    "                    tag_options = get_tag_options(cluster)\n",
    "                    start_tag = start_tag_template.format(*tag_options, \n",
    "                                                          largest_padding - padding_reduction * len(html_tag_list[span_start]['start']))\n",
    "\n",
    "\n",
    "                    html_tag_list[span_start]['start'].append((start_tag))\n",
    "                    # Subscript used in end\n",
    "                    html_tag_list[span_end]['end'].append((span_start, cluster_idx, end_tag, subscript))\n",
    "\n",
    "\n",
    "            html_string = HTML_START + '<div style=\"line-height: 3\">'\n",
    "            for token_idx, token in enumerate(doc_list):\n",
    "                if token_idx in bert_seg_idx:\n",
    "                    html_string += \"\\n<br/>\"\n",
    "                    \n",
    "                if token_idx in html_tag_list:\n",
    "                    for tag_type in ['end', 'start']:\n",
    "                        if tag_type == 'end' and (tag_type in html_tag_list[token_idx]):\n",
    "                            tags = html_tag_list[token_idx]['end']\n",
    "\n",
    "                            # Sort the tags so as to mimic the stack behavior\n",
    "                            tags = html_tag_list[token_idx]['end'][::-1] #sorted(tags, key=lambda x: x[0] - x[1] * 1e-5)  # Highest mentions first\n",
    "                            for _, _, html_tag, subscript in tags:\n",
    "                                html_string += \"<sub>\" + subscript + \"</sub>\" \n",
    "                                html_string += html_tag\n",
    "                                # Since we are deleting the highest indices first, the lower indices are unaffected\n",
    "\n",
    "                        if tag_type == 'start' and (tag_type in html_tag_list[token_idx]):\n",
    "                            for html_tag in html_tag_list[token_idx]['start']:\n",
    "                                html_string += html_tag\n",
    "\n",
    "                html_string += \" \" + token\n",
    "\n",
    "            html_string += \"</div></body></html>\"\n",
    "            html_string = html_string.replace(\"\\n\", \"\\n<br/>\")\n",
    "            html_string = html_string.replace(\"~\", \"&lt;\")\n",
    "            html_string = html_string.replace(\"^\", \"&gt;\")\n",
    "            \n",
    "            file_name = f\"({split}) \" + instance[\"doc_key\"].replace(\"/\", \"-\") + \".html\"\n",
    "            file_path = path.join(output_dir, file_name)\n",
    "            html_files.append(file_name)\n",
    "            with open(file_path, \"w\") as f:\n",
    "                f.write(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shtoshni/Research/events/models/html_vis/events_cb030fc0c2b8abdb996fc320c2321144/index.html\n"
     ]
    }
   ],
   "source": [
    "index_html = HTML_START + '<ol type=\"1\">'\n",
    "\n",
    "for html_file in html_files:\n",
    "    base_name = path.splitext(path.basename(html_file))[0].replace(\"-\", \"/\")\n",
    "    index_html += '<li> <a href=\"{}\", target=\"_blank\">'.format(html_file) + base_name + '</a></li>\\n'\n",
    "    \n",
    "index_html += '</ol>\\n</body>\\n</html>'\n",
    "index_file_path = path.join(output_dir, \"index.html\")\n",
    "print(index_file_path)\n",
    "with open(path.join(output_dir, \"index.html\"), \"w\") as g:\n",
    "    g.write(index_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:events]",
   "language": "python",
   "name": "conda-env-events-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
