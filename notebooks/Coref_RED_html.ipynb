{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from os import path\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils import get_ent_info, get_all_clusters_from_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/shtoshni/Research/events/data/red/data/source\"\n",
    "source_files = glob.glob(\"{}/*/*\".format(data_dir))\n",
    "\n",
    "ann_dir = \"/home/shtoshni/Research/events/data/red/data/simp_corr_annotation\"\n",
    "ann_files = glob.glob(\"{}/*/*\".format(ann_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEVEL = 0\n",
    "\n",
    "if LEVEL == 0:\n",
    "    # Just identical coref chains\n",
    "    output_dir = \"/home/shtoshni/Research/events/data/red/coref_red_html\"\n",
    "elif LEVEL == 1:\n",
    "    # Add appositive and bridging\n",
    "    output_dir = \"/home/shtoshni/Research/events/data/red/ap_br_id_red_html\"\n",
    "elif LEVEL == 2:\n",
    "    # Add set/member and whole/part to annotation as well\n",
    "    output_dir = \"/home/shtoshni/Research/events/data/red/se_wh_ap_br_id_red_html\"\n",
    "\n",
    "if not path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "HTML_START = '<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"UTF-8\"></head><body>'\n",
    "\n",
    "\n",
    "start_tag_template = '<div style=\"border:2px; display:inline; border-style: solid; border-color: {}; padding: 10px; padding-right: 3px; padding-left: 3px\">'\n",
    "\n",
    "entity_tag = start_tag_template.format('#0066CC')\n",
    "event_tag = start_tag_template.format('violet')\n",
    "\n",
    "end_tag = '</div>'\n",
    "\n",
    "type_to_start_tag = {}\n",
    "type_to_start_tag['IDENTICAL'] = 'ID'\n",
    "type_to_start_tag['APPOSITIVE'] = 'APPOS'\n",
    "type_to_start_tag['BRIDGING'] = 'BRIDG'\n",
    "type_to_start_tag['SET/MEMBER'] = 'S/M'\n",
    "type_to_start_tag['WHOLE/PART'] = 'W/P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_file in source_files:\n",
    "    # Read the source doc\n",
    "    source_lines = open(source_file).readlines()\n",
    "    source_str = \"\".join(source_lines)\n",
    "    \n",
    "    # Read the annotation file\n",
    "    base_name = path.basename(source_file)\n",
    "    dir_name = path.basename(path.dirname(source_file))\n",
    "    \n",
    "    ann_file = path.join(path.join(ann_dir, dir_name), base_name + \".RED-Relation.gold.completed.xml\")\n",
    "    \n",
    "    tree = ET.parse(ann_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Get info from the XML file\n",
    "    ent_map, ent_list = get_ent_info(root)\n",
    "    mention_to_cluster_info = get_all_clusters_from_xml(root, ent_map, LEVEL=LEVEL)\n",
    "    \n",
    "    html_tag_list = {}\n",
    "    \n",
    "    # Get all the entity info\n",
    "    for mention, cluster_info in mention_to_cluster_info.items():\n",
    "        ent_type, (span_start, span_end) = ent_map[mention]\n",
    "        if ent_type == 'ENTITY':\n",
    "            start_tag = entity_tag\n",
    "        elif ent_type == 'EVENT':\n",
    "            start_tag = event_tag\n",
    "\n",
    "        if span_start not in html_tag_list:\n",
    "            html_tag_list[span_start] = defaultdict(list)\n",
    "        if span_end not in html_tag_list:\n",
    "            html_tag_list[span_end] = defaultdict(list)\n",
    "        \n",
    "        subscript = ''\n",
    "        for idx, (cluster_type, cluster_idx) in enumerate(cluster_info):\n",
    "            if idx > 0:\n",
    "                subscript += \", \"\n",
    "            subscript += cluster_type + \" \" + str(cluster_idx)\n",
    "                \n",
    "\n",
    "        html_tag_list[span_start]['start'].append((mention, start_tag, ''))\n",
    "        # Subscript used in end\n",
    "        html_tag_list[span_end]['end'].append((mention, end_tag, subscript))\n",
    "    \n",
    "        \n",
    "    html_string = HTML_START + '<div style=\"line-height: 3\">'\n",
    "    \n",
    "    offset = 0 \n",
    "    counter = 0\n",
    "    source_str = source_str.replace(\"<\", \"~\")\n",
    "    source_str = source_str.replace(\">\", \"^\")\n",
    "    \n",
    "    # This list acts like a stack. We push the new mentions based on start tag\n",
    "    # and remove the mentions in the order of most recent to least recent.\n",
    "    mentions_processed = []\n",
    "    \n",
    "    for idx, token in enumerate(source_str):\n",
    "        if idx in html_tag_list:\n",
    "            for tag_type in ['end', 'start']:\n",
    "                if tag_type == 'end' and (tag_type in html_tag_list[idx]):\n",
    "                    tags = html_tag_list[idx]['end']\n",
    "    \n",
    "                    tags = [(mentions_processed.index(mention), html_tag, cluster_idx) \n",
    "                           for mention, html_tag, cluster_idx in tags]\n",
    "                    # Sort the tags so as to mimic the stack behavior\n",
    "                    tags = sorted(tags, key=lambda x: x[0], reverse=True)  # Highest mentions first\n",
    "                    for mention_idx, html_tag, cluster_info in tags:\n",
    "                        html_string += \"<sub>\" + cluster_info + \"</sub>\" \n",
    "                        html_string += html_tag\n",
    "                        # Since we are deleting the highest indices first, the lower indices are unaffected\n",
    "                        del mentions_processed[mention_idx]\n",
    "\n",
    "                if tag_type == 'start' and (tag_type in html_tag_list[idx]):\n",
    "                    for mention_id, html_tag, cluster_idx in html_tag_list[idx]['start']:\n",
    "                        # Add the mention_id to the current list of active mentions\n",
    "                        mentions_processed.append(mention_id)\n",
    "                        html_string += html_tag\n",
    "        \n",
    "        html_string += token\n",
    "            \n",
    "    html_string += \"</div></body></html>\"\n",
    "    html_string = html_string.replace(\"\\n\", \"\\n<br/>\")\n",
    "    html_string = html_string.replace(\"~\", \"&lt;\")\n",
    "    html_string = html_string.replace(\"^\", \"&gt;\")\n",
    "    with open(path.join(output_dir, base_name + \".html\"), \"w\") as f:\n",
    "        f.write(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_html = HTML_START + '<ol type=\"1\">'\n",
    "\n",
    "for source_file in source_files:\n",
    "    base_file = path.basename(source_file)\n",
    "    output_file = base_file + \".html\"\n",
    "    \n",
    "    index_html += '<li> <a href=\"{}\", target=\"_blank\">'.format(output_file) + base_file + '</a></li>\\n'\n",
    "    \n",
    "\n",
    "index_html += '</ol>\\n</body>\\n</html>'\n",
    "with open(path.join(output_dir, \"index.html\"), \"w\") as g:\n",
    "    g.write(index_html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coref]",
   "language": "python",
   "name": "conda-env-coref-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
