{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import os\n",
    "from os import path\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/shtoshni/Research/events/data/red/data/source\"\n",
    "source_files = glob.glob(\"{}/*/*\".format(data_dir))\n",
    "\n",
    "ann_dir = \"/home/shtoshni/Research/events/data/red/data/annotation\"\n",
    "ann_files = glob.glob(\"{}/*/*\".format(ann_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_file in source_files:\n",
    "    base_name = path.basename(source_file)\n",
    "    dir_name = path.basename(path.dirname(source_file))\n",
    "    \n",
    "    ann_file = path.join(path.join(ann_dir, dir_name), base_name + \".RED-Relation.gold.completed.xml\")\n",
    "\n",
    "    if ann_file in ann_files:\n",
    "        continue\n",
    "    else:\n",
    "        print(ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = \"/home/shtoshni/Research/events/data/red/data/source/deft/04debcc4da342dc971bdef4210fe468a.mpdf\"\n",
    "base_name = path.basename(source_file)\n",
    "dir_name = path.basename(path.dirname(source_file))\n",
    "ann_file = path.join(path.join(ann_dir, dir_name), base_name + \".RED-Relation.gold.completed.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'author'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lines = open(source_file).readlines()\n",
    "source_str = \"\".join(source_lines)\n",
    "source_str[73:79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(ann_file)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8731\n",
      "10319\n"
     ]
    }
   ],
   "source": [
    "event_counter = 0\n",
    "entity_counter = 0\n",
    "for source_file in source_files:\n",
    "    base_name = path.basename(source_file)\n",
    "    dir_name = path.basename(path.dirname(source_file))\n",
    "    \n",
    "    ann_file = path.join(path.join(ann_dir, dir_name), base_name + \".RED-Relation.gold.completed.xml\")\n",
    "\n",
    "    tree = ET.parse(ann_file)\n",
    "    root = tree.getroot()\n",
    "    for elem in root.iter('entity'):\n",
    "    #     print(dir(elem))\n",
    "        for sub_elem in elem.iter('type'):\n",
    "            if sub_elem.text == 'EVENT':\n",
    "                event_counter += 1\n",
    "            elif sub_elem.text == 'ENTITY':\n",
    "                entity_counter += 1\n",
    "    \n",
    "print(event_counter)\n",
    "print(entity_counter)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<', 'doc', 'id=', \"''\", '04debcc4da342dc971bdef4210fe468a', \"''\", '>', '<', 'headline', '>', '<', '/headline', '>', '<', 'post', 'author=', \"''\", 'Dick', 'here', \"''\", 'datetime=', \"''\", '2008-01-11T12:18:00', \"''\", 'id=', \"''\", 'p1', \"''\", '>', 'Do', \"n't\", 'order', 'anything', 'online', 'if', 'Amtrak', 'are', 'delivering', 'it', '-', 'here', \"'s\", 'my', 'experience', '.', 'Ordered', 'a', '32', \"''\", 'TV', 'online', ',', 'cheaper', 'than', 'Argos', '-', 'who', 'did', \"n't\", 'have', 'it', 'in', 'stock', '-', 'but', 'with', 'the', 'delivery', 'charge', 'the', 'cost', 'was', 'the', 'same', '.', 'Advised', 'that', 'it', 'would', 'be', 'delivered', 'by', 'Amtrak', 'on', 'Tuesday', '.', 'Tuesday', 'came', 'and', 'went', ',', 'no', 'sign', '.', 'Phoned', 'Amtrak', 'on', 'Wednesday', ',', '``', 'we', 'need', 'a', 'consignment', 'number', \"''\", '.', 'Phoned', 'online', 'company', 'and', 'got', 'it', '.', 'Phoned', 'Amtrak', '``', 'a', 'card', 'was', 'left', 'on', 'Tuesday', 'as', 'you', 'were', \"n't\", 'there', \"''\", '(', 'no', 'it', 'was', \"n't\", 'of', 'course', ')', ',', 'and', '``', 'we', \"'re\", 'not', 'allowed', 'to', 'leave', 'it', 'with', 'a', 'neighbour', \"''\", '.', 'Arranged', 'for', 'another', 'delivery', 'on', 'Saturday', '.', 'Arrived', 'home', 'yesterday', '-', 'it', 'had', 'been', 'delivered', 'next', 'door', 'yesterday', ',', 'with', 'a', 'card', 'saying', 'this', 'was', 'their', 'first', 'attempt', 'at', 'delivery', '...', 'What', 'a', 'bunch', 'of', 'jokers', '.', '<', '/post', '>', '<', '/doc', '>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68868"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counter = 0\n",
    "for source_file in source_files:\n",
    "    source_lines = open(source_file).readlines()\n",
    "    source_str = \"\".join(source_lines)\n",
    "    source_str = source_str.replace(\"\\n\", \" \")\n",
    "    \n",
    "    tokens = word_tokenize(source_str)\n",
    "    token_counter += len(tokens)\n",
    "    \n",
    "    if \"04debcc4da342dc971bdef4210fe468a\" in source_file:\n",
    "        print(tokens)\n",
    "    \n",
    "    \n",
    "token_counter       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweet Glory! DOCTIME\n",
      "Sweet Glory! TIMEX3\n",
      "Sweet Glory! TIMEX3\n",
      "Sweet Glory! TIMEX3\n",
      "Sweet Glory! TIMEX3\n",
      "Sweet Glory! TIMEX3\n",
      "Sweet Glory! TIMEX3\n",
      "Sweet Glory! TIMEX3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "replace() takes at least 2 arguments (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-da45807f257b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mhtml_string\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"</div></body></html>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mhtml_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n<br/>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mhtml_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/shtoshni/test.html\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() takes at least 2 arguments (0 given)"
     ]
    }
   ],
   "source": [
    "HTML_START = '<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"UTF-8\"></head><body>'\n",
    "\n",
    "entity_tag = '<div style=\"border:2px; display:inline; border-style: solid; border-color: coral; padding: 10px; padding-right: 3px; padding-left: 3px\">'\n",
    "event_tag = '<div style=\"border:2px; display : inline; border-style: solid; border-color: green; padding:10px; padding-right: 3px; padding-left: 3px\">'\n",
    "end_tag = '</div>'\n",
    "\n",
    "largest_padding = 11\n",
    "padding_reduction = 3\n",
    "\n",
    "for source_file in [\"/home/shtoshni/Research/events/data/red/data/source/deft/04debcc4da342dc971bdef4210fe468a.mpdf\"]:\n",
    "    # Read the source doc\n",
    "    source_lines = open(source_file).readlines()\n",
    "    source_str = \"\".join(source_lines)\n",
    "    \n",
    "    # Read the annotation file\n",
    "    base_name = path.basename(source_file)\n",
    "    dir_name = path.basename(path.dirname(source_file))\n",
    "    \n",
    "    ann_file = path.join(path.join(ann_dir, dir_name), base_name + \".RED-Relation.gold.completed.xml\")\n",
    "    \n",
    "    tree = ET.parse(ann_file)\n",
    "    root = tree.getroot()\n",
    "    entity_list = []\n",
    "    html_tag_list = defaultdict(list)\n",
    "    for elem in root.iter('entity'):\n",
    "        span_str = list(elem.iter('span'))[0].text\n",
    "        span_start, span_end = [int(endpoint) for endpoint in span_str.split(\",\")]\n",
    "        elem_id = list(elem.iter('id'))[0].text\n",
    "        elem_type = list(elem.iter('type'))[0].text\n",
    "        \n",
    "        entity_list.append((elem_id, elem_type, (span_start, span_end)))\n",
    "        \n",
    "        if elem_type == 'ENTITY':\n",
    "            html_tag = entity_tag\n",
    "        elif elem_type == 'EVENT':\n",
    "            html_tag = event_tag\n",
    "        else:\n",
    "            print(\"Sweet Glory! {}\".format(elem_type))\n",
    "        \n",
    "        html_tag_list[span_start].append((html_tag, 'start'))\n",
    "        html_tag_list[span_end].append((end_tag, 'end'))\n",
    "        \n",
    "    \n",
    "    entity_list = sorted(entity_list, key=lambda x: x[2][0])\n",
    "    \n",
    "    for key in html_tag_list:\n",
    "        # Sort all the HTML tags so that the end tags occur before the start tags\n",
    "        html_tag_list[key] = sorted(html_tag_list[key], key=lambda x: x[1])\n",
    "#     html_tag_list = sorted(html_tag_list, key=lambda x: x[1])\n",
    "    \n",
    "    html_string = HTML_START + '<div style=\"line-height: 3\">'\n",
    "    \n",
    "    offset = 0 \n",
    "    counter = 0\n",
    "    source_str = source_str.replace(\"<\", \"~\")\n",
    "    source_str = source_str.replace(\">\", \"^\")\n",
    "    for idx, token in enumerate(source_str):\n",
    "        if idx in html_tag_list:\n",
    "            tags = html_tag_list[idx]\n",
    "            for tag, _ in tags:\n",
    "                html_string += tag\n",
    "        \n",
    "        html_string += token\n",
    "            \n",
    "        \n",
    "    html_string += \"</div></body></html>\"\n",
    "    html_string = html_string.replace(\"\\n\", \"\\n<br/>\")\n",
    "    html_string = html_string.replace(\"~\", \"&lt;\")\n",
    "    html_string = html_string.replace(\"^\", \"&gt;\")\n",
    "    with open(\"/home/shtoshni/test.html\", \"w\") as f:\n",
    "        f.write(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:narrative_10] *",
   "language": "python",
   "name": "conda-env-narrative_10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
