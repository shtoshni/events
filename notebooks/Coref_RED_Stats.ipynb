{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from os import path\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_ent_info, get_clusters_from_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/shtoshni/Research/events/data/red/data/source\"\n",
    "source_files = glob.glob(\"{}/*/*\".format(data_dir))\n",
    "\n",
    "ann_dir = \"/home/shtoshni/Research/events/data/red/data/annotation\"\n",
    "ann_files = glob.glob(\"{}/*/*\".format(ann_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/shtoshni/Research/events/data/red/stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5c0dd992beaff240f732e0fdacbd49e4.mpdf: Num issues 6\n",
      "NYT_ENG_20130424.0047: Num issues 4\n",
      "alt.support.divorce_20050113.2451: Num issues 3\n",
      "NYT_ENG_20131225.0200: Num issues 2\n",
      "APW_ENG_20101231.0037: Num issues 2\n",
      "soc.culture.iraq_20050211.0445: Num issues 2\n",
      "uk.gay-lesbian-bi_20050127.0311: Num issues 2\n",
      "soc.culture.china_20050203.0639: Num issues 2\n",
      "PROXY_AFP_ENG_20020404_0305: Num issues 2\n",
      "NYT_ENG_20130613.0153: Num issues 1\n",
      "NYT_ENG_20130619.0092: Num issues 1\n",
      "XIN_ENG_20101125.0137: Num issues 1\n",
      "4829d3d91263ed9d8801e6d94c3569a5.mpdf: Num issues 1\n",
      "5c59566e9132c060423cad5b2d1bac1e.mpdf: Num issues 1\n",
      "57026b7bcb8f855de3e26d572db35285: Num issues 1\n",
      "alt.sys.pc-clone.dell_20050226.2350: Num issues 1\n",
      "misc.legal.moderated_20050129.2225: Num issues 1\n",
      "44b011cd504c9ed71beb851324db886a: Num issues 1\n",
      "0f03cc5a508d630c6c8c8c61396e31a9: Num issues 1\n",
      "PROXY_AFP_ENG_20020414_0542: Num issues 1\n"
     ]
    }
   ],
   "source": [
    "num_chains = defaultdict(int) \n",
    "num_mentions = defaultdict(int)\n",
    "num_singletons = defaultdict(int)\n",
    "chain_lengths = defaultdict(list)\n",
    "\n",
    "\n",
    "files_with_issues = defaultdict(int)\n",
    "\n",
    "for source_file in source_files:\n",
    "    # Read the source doc\n",
    "    source_lines = open(source_file).readlines()\n",
    "    source_str = \"\".join(source_lines)\n",
    "    \n",
    "    # Read the annotation file\n",
    "    base_name = path.basename(source_file)\n",
    "    dir_name = path.basename(path.dirname(source_file))\n",
    "    \n",
    "    ann_file = path.join(path.join(ann_dir, dir_name), base_name + \".RED-Relation.gold.completed.xml\")\n",
    "    \n",
    "    tree = ET.parse(ann_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Get info from the XML file\n",
    "    ent_map, ent_list = get_ent_info(root)\n",
    "    clusters = get_clusters_from_xml(root, ent_map)\n",
    "    \n",
    "    doc_mentions = defaultdict(int)\n",
    "    \n",
    "    for _, (ent_type, (_, _)) in ent_map.items():\n",
    "        num_mentions[ent_type] += 1\n",
    "        doc_mentions[ent_type] += 1\n",
    "        \n",
    "    clustered_mentions = defaultdict(int)\n",
    "    \n",
    "    all_clustered_mentions = set()\n",
    "    for cluster in clusters:\n",
    "        # Check the entity type of the first element in the cluster\n",
    "        cluster_type = ent_map[cluster[0]][0]\n",
    "        \n",
    "        num_chains[cluster_type] += 1\n",
    "        chain_lengths[cluster_type].append(len(cluster))\n",
    "        \n",
    "        \n",
    "        for mention in cluster:\n",
    "            elem_type, (span_start, span_end) = ent_map[mention]\n",
    "            if mention in all_clustered_mentions:\n",
    "                # Not supposed to happen\n",
    "#                 print(\"{}: {} - \\\"{}\\\" is not uniquely clustered\\n\".format(\n",
    "#                     base_name, mention, source_str[span_start: span_end]))        \n",
    "                files_with_issues[base_name] += 1\n",
    "        \n",
    "            # Add mention to all mentions\n",
    "            all_clustered_mentions.add(mention)\n",
    "            \n",
    "            try:\n",
    "                assert (elem_type == cluster_type)  # Type of cluster should be consistent\n",
    "            except AssertionError:\n",
    "#                 print(\"Type of cluster {} and element {} don't match\".format(cluster_type, elem_type))\n",
    "#                 print(\"{}, Element: {}\\n\".format(base_name, mention))\n",
    "                files_with_issues[base_name] += 1\n",
    "    \n",
    "            # Update the count of different mention types\n",
    "            clustered_mentions[elem_type] += 1\n",
    "    \n",
    "    for ent_type in ['EVENT', 'ENTITY']:\n",
    "        num_singletons[ent_type] += doc_mentions[ent_type] - clustered_mentions[ent_type]\n",
    "    \n",
    "files_with_issues = sorted(files_with_issues.items(), key=lambda x: x[1], reverse=True)\n",
    "for file_name, num_issues in files_with_issues:\n",
    "    print(\"{}: Num issues {}\".format(file_name, num_issues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files with issues: 20\n",
      "Number of Entity Mentions: 10319\n",
      "Number of Event Mentions: 8731\n",
      "\n",
      "Number of Entity Chains: 1287\n",
      "Number of Event Chains: 762\n",
      "\n",
      "Number of Singleton Entity Mentions: 3880\n",
      "Number of Singleton Event Mentions: 6609\n",
      "\n",
      "Mean Entity chain length: 5.00\n",
      "Max Entity chain length: 82\n",
      "Mean Event chain length: 2.79\n",
      "Max Event chain length: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"# of files with issues:\", len(files_with_issues))\n",
    "\n",
    "for metric, metric_str in zip([num_mentions, num_chains, num_singletons],\n",
    "                              ['{} Mentions', '{} Chains', 'Singleton {} Mentions']):\n",
    "    for mention_type in ['ENTITY', 'EVENT']:\n",
    "        print((\"Number of \" + metric_str + \": {}\").format(mention_type.capitalize(), metric[mention_type]))\n",
    "    print()\n",
    "    \n",
    "# print(\"Number of Entity Mentions:\", num_mentions['ENTITY'])\n",
    "# print(\"Number of Event Mentions:\", num_mentions['EVENT'])\n",
    "\n",
    "# print(\"Number of Entity Chains:\", num_chains['ENTITY'])\n",
    "# print(\"Number of Event Chains:\", num_chains['EVENT'])\n",
    "\n",
    "# print(\"Number of Singleton Entity Mentions:\", num_singleton_entities)\n",
    "# print(\"Number of Singleton Event Mentions:\", num_singleton_events)\n",
    "\n",
    "for mention_type in ['ENTITY', 'EVENT']:\n",
    "    mention_str = mention_type.capitalize()\n",
    "    type_chain_lengths = np.asarray(chain_lengths[mention_type])\n",
    "    print(\"Mean {} chain length: {:.2f}\".format(mention_str, np.mean(type_chain_lengths)))\n",
    "    print(\"Max {} chain length: {}\".format(mention_str, np.max(type_chain_lengths)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:narrative_10]",
   "language": "python",
   "name": "conda-env-narrative_10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
