{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import json\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(\"/home/shtoshni/Research/events/src/\")\n",
    "from kbp_2015_utils.constants import EVENT_SUBTYPES\n",
    "\n",
    "# from red_utils.constants import IDX_TO_ELEM_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set input and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file = \"/home/shtoshni/Research/events/proc_data/kbp_2015\"\n",
    "# output_dir = \"/home/shtoshni/Research/events/data/kbp_2014-2015/bert_html\"\n",
    "input_file = \"/home/shtoshni/Research/events/models/ment_kbp_2015_cleaned_mlp_1000_model_base_emb_attn_type_spanbert_segments_3_width_4_ft/valid.log.jsonl\"\n",
    "base_output_dir = \"/home/shtoshni/Research/events/models/html/ment_detection\"\n",
    "\n",
    "model_name = path.basename(path.dirname(input_file))\n",
    "output_dir = path.join(base_output_dir, model_name)\n",
    "if not path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_START = '<!DOCTYPE html><html lang=\"en\"><head><meta charset=\"UTF-8\"></head><body>'\n",
    "\n",
    "\n",
    "start_tag_template = '<div style=\"border:2px; display:inline; border-style: {}; border-color: {}; padding: {}px; padding-right: 3px; padding-left: 3px\">'\n",
    "end_tag = '</div>'\n",
    "\n",
    "largest_padding = 14\n",
    "padding_reduction = 3\n",
    "\n",
    "\n",
    "def get_tag_options(tag_type=\"gt\"):\n",
    "    border = 'solid'\n",
    "        \n",
    "    color = '#FFD700'\n",
    "    if tag_type == \"pred\":\n",
    "        color = 'red'\n",
    "        \n",
    "    return (border, color)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_files = []\n",
    "\n",
    "\n",
    "with open(input_file) as f:\n",
    "    for line in f:\n",
    "        instance = json.loads(line.strip())\n",
    "\n",
    "        bert_seg_idx = []\n",
    "        doc_list = [] \n",
    "        for sentence in instance[\"sentences\"]:\n",
    "            doc_list.extend(sentence)\n",
    "            bert_seg_idx.append(len(sentence) + (bert_seg_idx[-1] if len(bert_seg_idx) else 0))\n",
    "\n",
    "        bert_seg_idx = set(bert_seg_idx)\n",
    "        html_tag_list = {}\n",
    "\n",
    "        # Get all the entity info\n",
    "        for mention_type in [\"gt_mentions\", \"pred_mentions\"]:\n",
    "            tag_type = mention_type.split(\"_\")[0]\n",
    "            mentions = sorted(instance[mention_type], key=lambda x: x[0] + 1e-4 * x[1] + 1e-6 * x[2])\n",
    "            for mention_idx, mention in enumerate(mentions):\n",
    "                if \"gt_\" in mention_type:\n",
    "                    span_start, span_end, event_subtype_val = mention\n",
    "                    ent_type = f'{EVENT_SUBTYPES[event_subtype_val]} {mention_idx}'\n",
    "                else:\n",
    "                    span_start, span_end, event_subtype_val = mention\n",
    "                    ent_type = f'{EVENT_SUBTYPES[event_subtype_val]} {mention_idx}'\n",
    "\n",
    "                span_end = span_end + 1  ## Now span_end is not part of the span\n",
    "                \n",
    "                if span_start not in html_tag_list:\n",
    "                    html_tag_list[span_start] = defaultdict(list)\n",
    "                if span_end not in html_tag_list:\n",
    "                    html_tag_list[span_end] = defaultdict(list)\n",
    "\n",
    "                subscript = ent_type\n",
    "\n",
    "                tag_options = get_tag_options(tag_type)\n",
    "                start_tag = start_tag_template.format(*tag_options, \n",
    "                                                      largest_padding - padding_reduction * len(html_tag_list[span_start]['start']))\n",
    "\n",
    "\n",
    "                html_tag_list[span_start]['start'].append((start_tag))\n",
    "                # Subscript used in end\n",
    "                html_tag_list[span_end]['end'].append((span_start, mention_idx, end_tag, subscript))\n",
    "\n",
    "\n",
    "        html_string = HTML_START + '<div style=\"line-height: 3\">'\n",
    "        for token_idx, token in enumerate(doc_list):\n",
    "            if token_idx in bert_seg_idx:\n",
    "                html_string += \"\\n<br/>\"\n",
    "\n",
    "            if token_idx in html_tag_list:\n",
    "                for tag_type in ['end', 'start']:\n",
    "                    if tag_type == 'end' and (tag_type in html_tag_list[token_idx]):\n",
    "                        tags = html_tag_list[token_idx]['end']\n",
    "\n",
    "                        # Sort the tags so as to mimic the stack behavior\n",
    "                        tags = tags[::-1]  # Highest mentions first\n",
    "                        for _, _, html_tag, subscript in tags:\n",
    "                            html_string += \"<sub>\" + subscript + \"</sub>\" \n",
    "                            html_string += html_tag\n",
    "                            # Since we are deleting the highest indices first, the lower indices are unaffected\n",
    "\n",
    "                    if tag_type == 'start' and (tag_type in html_tag_list[token_idx]):\n",
    "                        for html_tag in html_tag_list[token_idx]['start']:\n",
    "                            html_string += html_tag\n",
    "\n",
    "            html_string += \" \" + token\n",
    "\n",
    "        html_string += \"</div></body></html>\"\n",
    "        html_string = html_string.replace(\"\\n\", \"\\n<br/>\")\n",
    "        html_string = html_string.replace(\"~\", \"&lt;\")\n",
    "        html_string = html_string.replace(\"^\", \"&gt;\")\n",
    "\n",
    "        file_name = instance[\"doc_key\"].replace(\"/\", \"-\") + f\"- ({instance['f_score']})\" + \".html\"\n",
    "#         print(file_name)\n",
    "        file_path = path.join(output_dir, file_name)\n",
    "        html_files.append(file_name)\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shtoshni/Research/events/models/html/ment_detection/ment_kbp_2015_cleaned_mlp_1000_model_base_emb_attn_type_spanbert_segments_3_width_4_ft/index.html\n"
     ]
    }
   ],
   "source": [
    "index_html = HTML_START + '<ol type=\"1\">'\n",
    "\n",
    "for html_file in html_files:\n",
    "    base_name = path.splitext(path.basename(html_file))[0].replace(\"-\", \"/\")\n",
    "    index_html += '<li> <a href=\"{}\", target=\"_blank\">'.format(html_file) + base_name + '</a></li>\\n'\n",
    "    \n",
    "index_html += '</ol>\\n</body>\\n</html>'\n",
    "index_file_path = path.join(output_dir, \"index.html\")\n",
    "print(index_file_path)\n",
    "with open(path.join(output_dir, \"index.html\"), \"w\") as g:\n",
    "    g.write(index_html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:events] *",
   "language": "python",
   "name": "conda-env-events-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
