{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from os import path\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import Image\n",
    "import shutil\n",
    "\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/shtoshni/Research/events/data/kbp_2014-2015/data/2015\"\n",
    "\n",
    "split_to_subdir_dict = {\n",
    "    \"training\": {\"source\": \"source\", \"mention\": \"event_nugget\", \"coref\": \"event_hopper\"},\n",
    "    \"eval\": {\"source\": \"source\", \"mention\": \"nugget\", \"coref\": \"hopper\"}\n",
    "}\n",
    "\n",
    "file_suffix_dict = {\"source\":\".txt\", \"mention\": \".event_nuggets.xml\", \"coref\": \".event_hoppers.xml\"}\n",
    "\n",
    "proposed_splits = [(\"mod_training\", 128), (\"mod_dev\", 30)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all Doc IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = path.join(base_dir, \"training\")\n",
    "\n",
    "source_files = sorted(glob.glob(path.join(path.join(training_dir, \"source\"), \"*.txt\")))\n",
    "doc_ids = [path.splitext(path.basename(source_file))[0] for source_file in source_files]\n",
    "\n",
    "# Shuffle\n",
    "random.seed(10)\n",
    "random.shuffle(doc_ids)\n",
    "\n",
    "\n",
    "proposed_split_to_doc_ids = {}\n",
    "offset = 0\n",
    "for proposed_split, split_size in proposed_splits:\n",
    "    proposed_split_to_doc_ids[proposed_split] = doc_ids[offset: offset + split_size]\n",
    "    offset += split_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory structure for proposed splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proposed_split, doc_ids in proposed_split_to_doc_ids.items():\n",
    "    split_dir = path.join(base_dir, proposed_split)\n",
    "    if not path.exists(split_dir):\n",
    "        os.makedirs(split_dir)\n",
    "    \n",
    "    training_subdir_dict = split_to_subdir_dict[\"training\"]\n",
    "    # Create the same subdirectory structure as eval\n",
    "    subdir_dict = split_to_subdir_dict[\"eval\"]\n",
    "    for category, subdir in subdir_dict.items():\n",
    "        split_subdir = path.join(split_dir, subdir)\n",
    "        if not path.exists(split_subdir):\n",
    "            os.makedirs(split_subdir)\n",
    "        \n",
    "        # Corresponding training subdirectory\n",
    "        training_subdir = path.join(training_dir, training_subdir_dict[category])\n",
    "        \n",
    "        # File suffix for this subdirectory\n",
    "        file_suffix = file_suffix_dict[category]\n",
    "        \n",
    "        for doc_id in doc_ids:\n",
    "            src_file_path = path.join(training_subdir, doc_id + file_suffix)\n",
    "            dest_file_path = path.join(split_subdir, doc_id + file_suffix)\n",
    "            \n",
    "            shutil.copy(src_file_path, dest_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:events] *",
   "language": "python",
   "name": "conda-env-events-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
